{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T22:22:10.606129Z",
     "start_time": "2018-05-29T22:22:09.056198Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T22:22:10.646246Z",
     "start_time": "2018-05-29T22:22:10.608024Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class PerceptronClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, max_iteration=1000, lr=0.01):\n",
    "        self.max_iteration = max_iteration\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        rows,columns = X.shape\n",
    "        weight = np.ones(columns)\n",
    "        bias = 0\n",
    "        train_data = np.concatenate((X, np.array(y).reshape(rows,1)), axis=1)\n",
    "        # gradient descent\n",
    "        for i in range(self.max_iteration):\n",
    "            for sample in train_data:\n",
    "                x,y = sample[:-1],sample[-1]\n",
    "                y = 1 if y == 1 else -1\n",
    "                predict = np.dot(weight,x.T) + bias\n",
    "                if y * predict < 0: # 错分样本才更新权重\n",
    "                    weight = weight - self.lr * x\n",
    "                    bias = bias - self.lr * 1\n",
    "        self.weight = weight\n",
    "        self.bias = bias\n",
    "        return self\n",
    "    def predict(self, X, y=None):\n",
    "        result = []\n",
    "        for i in range(len(X)):\n",
    "            prediction = np.dot(self.weight, X[i].T) + self.bias\n",
    "            if prediction > 0:\n",
    "                result.append(1)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        return result\n",
    "    \n",
    "    def predict_proba(self, X, y=None):\n",
    "        result = []\n",
    "        for i in range(len(X)):\n",
    "            prediction = np.dot(self.weight, X[i].T) + self.bias\n",
    "            if prediction > 0:\n",
    "                result.append([0, 1])\n",
    "            else:\n",
    "                result.append([1, 0])\n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T22:22:10.707970Z",
     "start_time": "2018-05-29T22:22:10.648880Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class RelaxationClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, max_iteration=1000, lr=0.01, b=0.1):\n",
    "        self.max_iteration = max_iteration\n",
    "        self.b = b\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        rows, columns = X.shape\n",
    "        weight_aug = np.ones(X.shape[1] + 1)\n",
    "        X_aug = np.column_stack((X, np.ones(len(X))))\n",
    "        # gradient descent\n",
    "        for _ in range(self.max_iteration):\n",
    "            for row_id in range(len(X_aug)):\n",
    "                prediction = np.dot(weight_aug, X_aug[row_id].T) - self.b\n",
    "                y[row_id] = 1 if y[row_id] == 1 else -1\n",
    "                if y[row_id] * prediction < 0: # 错分样本才更新权重\n",
    "                    weight_aug = weight_aug - self.lr * prediction / np.linalg.norm(X_aug[row_id]) * X_aug[row_id].T\n",
    "        self.weight_aug = weight_aug\n",
    "        return self\n",
    "    def predict(self, X, y=None):\n",
    "        result = []\n",
    "        X_aug = np.column_stack((X, np.ones(len(X))))\n",
    "        for row_id in range(len(X)):\n",
    "            prediction = np.dot(self.weight_aug, X_aug[row_id].T) - self.b\n",
    "            if prediction > 0:\n",
    "                result.append(1)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        return result\n",
    "    \n",
    "    def predict_proba(self, X, y=None):\n",
    "        result = []\n",
    "        X_aug = np.column_stack((X, np.ones(len(X))))\n",
    "        for row_id in range(len(X)):\n",
    "            prediction = np.dot(self.weight_aug, X_aug[row_id].T) - self.b\n",
    "            if prediction > 0:\n",
    "                result.append([0, 1])\n",
    "            else:\n",
    "                result.append([1, 0])\n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T22:22:10.761972Z",
     "start_time": "2018-05-29T22:22:10.710083Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class MSEClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, threshold=1, lr=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        rows, columns = X.shape\n",
    "        weight_aug = np.ones(X.shape[1] + 1)\n",
    "        X_aug = np.column_stack((X, np.ones(len(X))))\n",
    "        for i in range(rows):\n",
    "            if y[i] == 0: X_aug[i] = -1 * X_aug[i]\n",
    "        b = np.ones(len(X))\n",
    "        # gradient descent\n",
    "        delta = 9999\n",
    "        k = 0\n",
    "        while delta > self.threshold:\n",
    "            row_id = k % len(X)\n",
    "            delta_vector = self.lr * (np.dot(b[row_id] - np.dot(weight_aug, X_aug[row_id].T), X_aug[row_id].T))\n",
    "            weight_aug = weight_aug + delta_vector\n",
    "            delta = np.linalg.norm(delta_vector)\n",
    "            k += 1\n",
    "        self.weight_aug = weight_aug\n",
    "        return self\n",
    "    def predict(self, X, y=None):\n",
    "        result = []\n",
    "        X_aug = np.column_stack((X, np.ones(len(X))))\n",
    "        for row_id in range(len(X)):\n",
    "            prediction = np.dot(self.weight_aug, X_aug[row_id].T)\n",
    "            if prediction > 0:\n",
    "                result.append(1)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        return result\n",
    "    \n",
    "    def predict_proba(self, X, y=None):\n",
    "        result = []\n",
    "        X_aug = np.column_stack((X, np.ones(len(X))))\n",
    "        for row_id in range(len(X)):\n",
    "            prediction = np.dot(self.weight_aug, X_aug[row_id].T)\n",
    "            if prediction > 0:\n",
    "                result.append([0, 1])\n",
    "            else:\n",
    "                result.append([1, 0])\n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T22:41:12.195579Z",
     "start_time": "2018-05-29T22:41:12.131535Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class FisherClassifier(BaseEstimator, ClassifierMixin):      \n",
    "    def compute_cov_mean(self,x):\n",
    "        u = np.mean(x, axis=0)\n",
    "        cov = np.zeros((x.shape[1], x.shape[1]))\n",
    "        for s in x:\n",
    "            temp = (s - u).reshape(4, 1)\n",
    "            cov += np.dot(temp, temp.T)\n",
    "        return cov,u\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        num_train,num_features = X.shape\n",
    "        x_1 = X[np.where(y == 1)]\n",
    "        x_2 = X[np.where(y == 0)]\n",
    "        conv1, u1 = self.compute_cov_mean(x_1)\n",
    "        conv2, u2 = self.compute_cov_mean(x_2)\n",
    "        SW = conv1 + conv2\n",
    "        u, s, v = np.linalg.svd(SW)\n",
    "        sw_inv = np.dot(np.dot(v.T, np.linalg.inv(np.diag(s))), u.T)\n",
    "        self.W = np.dot(sw_inv,u1-u2)\n",
    "        w_conv = self.W\n",
    "        y_space1 = np.dot(x_1, w_conv)\n",
    "        uy1 = np.mean(y_space1)\n",
    "        y_space2 = np.dot(x_2, w_conv)\n",
    "        uy2 = np.mean(y_space2)\n",
    "        self.b = -1/2*(uy1+uy2)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        result = []\n",
    "        for row_id in range(len(X)):\n",
    "            prediction = np.dot(self.W, X[row_id].T) + self.b\n",
    "            if prediction > 0:\n",
    "                result.append(1)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        return result\n",
    "    \n",
    "    def predict_proba(self, X, y=None):\n",
    "        result = []\n",
    "        for row_id in range(len(X)):\n",
    "            prediction = np.dot(self.W, X[row_id].T) + self.b\n",
    "            if prediction > 0:\n",
    "                result.append([0, 1])\n",
    "            else:\n",
    "                result.append([1, 0])\n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T22:22:10.882086Z",
     "start_time": "2018-05-29T22:22:10.823977Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class HKClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, max_iteration=1000, lr=0.01):\n",
    "        self.max_iteration = max_iteration\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        num_train, num_features = X.shape\n",
    "        xone = np.ones((num_train, 1))\n",
    "        x = np.column_stack((xone, X))\n",
    "        x[np.where(y == 0)] = x[np.where(y == 0)] * -1\n",
    "        #权重和偏置初始化\n",
    "        self.W = np.ones((num_features+1))\n",
    "        Y = x\n",
    "        Ywn = np.linalg.pinv(Y)\n",
    "        bias = np.ones((num_train,))\n",
    "        bmin = 1e-6\n",
    "        flag = False\n",
    "        for i in range (self.max_iteration):\n",
    "            temp = np.array(np.dot(Y,self.W))\n",
    "            Evector = temp-bias\n",
    "            Evector_ = 1/2 * np.add(Evector, np.absolute(Evector))\n",
    "            bias = np.add(2 * self.lr * Evector_, bias)\n",
    "            self.W = np.dot(Ywn, bias)\n",
    "            for row in Evector_:\n",
    "                if (np.absolute(row) <= bmin):\n",
    "                    # reach bmin. End.\n",
    "                    flag = True\n",
    "                    break\n",
    "            if flag: break\n",
    "        self.b = self.W[0]\n",
    "        self.W = self.W[1:]\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        result = []\n",
    "        for row_id in range(len(X)):\n",
    "            prediction = np.dot(self.W, X[row_id].T) + self.b\n",
    "            if prediction > 0:\n",
    "                result.append(1)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        return result\n",
    "    \n",
    "    def predict_proba(self, X, y=None):\n",
    "        result = []\n",
    "        for row_id in range(len(X)):\n",
    "            prediction = np.dot(self.W, X[row_id].T) + self.b\n",
    "            if prediction > 0:\n",
    "                result.append([0, 1])\n",
    "            else:\n",
    "                result.append([1, 0])\n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T22:22:10.905140Z",
     "start_time": "2018-05-29T22:22:10.884241Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "import operator\n",
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "class KNNClassifier():\n",
    "    def __init__(self, k=5):\n",
    "        self.k = 5\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def distance(self, x, y):\n",
    "        X = np.vstack([x,y])\n",
    "        return pdist(X)\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        result = []\n",
    "        for row_id in range(len(X)):\n",
    "            distances = []\n",
    "            for index in range(len(self.X)):\n",
    "                dis = self.distance(self.X[index], X[row_id])[0]\n",
    "                distances.append([index, dis, self.y[index]])\n",
    "            distances = sorted(distances, key=lambda x: x[1])\n",
    "            labels = [distances[i][2] for i in range(self.k)]\n",
    "            result.append(Counter(labels).most_common(1)[0][0])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T22:22:10.996604Z",
     "start_time": "2018-05-29T22:22:10.909065Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "x_all = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
    "y_all = iris['target']\n",
    "test_ratio = 0.8\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all.as_matrix(), y_all, test_size=test_ratio, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T22:41:15.548118Z",
     "start_time": "2018-05-29T22:41:13.717391Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron OVO: 0.6916666666666667\n",
      "Perceptron OVR: 0.30833333333333335\n",
      "Relaxation OVO: 0.8833333333333333\n",
      "Relaxation OVR: 0.675\n",
      "Fisher OVO: 0.95\n",
      "Fisher OVR: 0.7333333333333333\n",
      "MSE OVO: 0.30833333333333335\n",
      "MSE OVR: 0.30833333333333335\n",
      "Ho-Kashyap OVO: 0.9583333333333334\n",
      "Ho-Kashyap OVR: 0.7333333333333333\n",
      "KNN: 0.9416666666666667\n",
      "SVM(rbf) OVO: 0.975\n",
      "SVM(rbf) OVR: 0.9666666666666667\n",
      "SVM(linear) OVO: 0.9666666666666667\n",
      "SVM(linear) OVR: 0.775\n",
      "SVM(poly) OVO: 0.95\n",
      "SVM(poly) OVR: 0.95\n",
      "SVM(sigmoid) OVO: 0.30833333333333335\n",
      "SVM(sigmoid) OVR: 0.30833333333333335\n"
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "model = OneVsOneClassifier(PerceptronClassifier())\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Perceptron OVO: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "model = OneVsRestClassifier(PerceptronClassifier())\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Perceptron OVR: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "# Relaxation\n",
    "model = OneVsOneClassifier(RelaxationClassifier())\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Relaxation OVO: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "model = OneVsRestClassifier(RelaxationClassifier())\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Relaxation OVR: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "# Fisher\n",
    "model = OneVsOneClassifier(FisherClassifier())\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Fisher OVO: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "model = OneVsRestClassifier(FisherClassifier())\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Fisher OVR: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "# MSE\n",
    "model = OneVsOneClassifier(MSEClassifier())\n",
    "model.fit(x_train, y_train)\n",
    "print(\"MSE OVO: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "model = OneVsRestClassifier(MSEClassifier())\n",
    "model.fit(x_train, y_train)\n",
    "print(\"MSE OVR: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "# Ho-Kashyap\n",
    "model = OneVsOneClassifier(HKClassifier())\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Ho-Kashyap OVO: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "model = OneVsRestClassifier(HKClassifier())\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Ho-Kashyap OVR: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "# KNN\n",
    "model = KNNClassifier(k=5)\n",
    "model.fit(x_train, y_train)\n",
    "model.predict(x_test)\n",
    "print(\"KNN: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "# SVM\n",
    "model = OneVsOneClassifier(SVC(kernel='rbf'))\n",
    "model.fit(x_train, y_train)\n",
    "print(\"SVM(rbf) OVO: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "model = OneVsRestClassifier(SVC(kernel='rbf'))\n",
    "model.fit(x_train, y_train)\n",
    "print(\"SVM(rbf) OVR: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "model = OneVsOneClassifier(SVC(kernel='linear'))\n",
    "model.fit(x_train, y_train)\n",
    "print(\"SVM(linear) OVO: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "model = OneVsRestClassifier(SVC(kernel='linear'))\n",
    "model.fit(x_train, y_train)\n",
    "print(\"SVM(linear) OVR: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "model = OneVsOneClassifier(SVC(kernel='poly'))\n",
    "model.fit(x_train, y_train)\n",
    "print(\"SVM(poly) OVO: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "model = OneVsRestClassifier(SVC(kernel='poly'))\n",
    "model.fit(x_train, y_train)\n",
    "print(\"SVM(poly) OVR: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "model = OneVsOneClassifier(SVC(kernel='sigmoid'))\n",
    "model.fit(x_train, y_train)\n",
    "print(\"SVM(sigmoid) OVO: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))\n",
    "model = OneVsRestClassifier(SVC(kernel='sigmoid'))\n",
    "model.fit(x_train, y_train)\n",
    "print(\"SVM(sigmoid) OVR: {}\".format(accuracy_score(y_test, model.predict(x_test), normalize=True)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
